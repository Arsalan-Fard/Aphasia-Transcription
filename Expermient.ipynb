{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import warnings\n",
    "import numpy\n",
    "import utils\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"whisper\")\n",
    "import faster_whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_model_langs = [\n",
    "    \"en\",\n",
    "    \"fr\",\n",
    "    \"de\",\n",
    "    \"es\",\n",
    "    \"it\",\n",
    "    \"nl\",\n",
    "    \"pt\",\n",
    "    \"bg\",\n",
    "    \"pl\",\n",
    "    \"cs\",\n",
    "    \"sk\",\n",
    "    \"sl\",\n",
    "]\n",
    "\n",
    "LANGUAGES = {\n",
    "    \"en\": \"english\",\n",
    "    \"zh\": \"chinese\",\n",
    "    \"de\": \"german\",\n",
    "    \"es\": \"spanish\",\n",
    "    \"ru\": \"russian\",\n",
    "    \"ko\": \"korean\",\n",
    "    \"fr\": \"french\",\n",
    "    \"ja\": \"japanese\",\n",
    "    \"pt\": \"portuguese\",\n",
    "    \"tr\": \"turkish\",\n",
    "    \"pl\": \"polish\",\n",
    "    \"ca\": \"catalan\",\n",
    "    \"nl\": \"dutch\",\n",
    "    \"ar\": \"arabic\",\n",
    "    \"sv\": \"swedish\",\n",
    "    \"it\": \"italian\",\n",
    "    \"id\": \"indonesian\",\n",
    "    \"hi\": \"hindi\",\n",
    "    \"fi\": \"finnish\",\n",
    "    \"vi\": \"vietnamese\",\n",
    "    \"he\": \"hebrew\",\n",
    "    \"uk\": \"ukrainian\",\n",
    "    \"el\": \"greek\",\n",
    "    \"ms\": \"malay\",\n",
    "    \"cs\": \"czech\",\n",
    "    \"ro\": \"romanian\",\n",
    "    \"da\": \"danish\",\n",
    "    \"hu\": \"hungarian\",\n",
    "    \"ta\": \"tamil\",\n",
    "    \"no\": \"norwegian\",\n",
    "    \"th\": \"thai\",\n",
    "    \"ur\": \"urdu\",\n",
    "    \"hr\": \"croatian\",\n",
    "    \"bg\": \"bulgarian\",\n",
    "    \"lt\": \"lithuanian\",\n",
    "    \"la\": \"latin\",\n",
    "    \"mi\": \"maori\",\n",
    "    \"ml\": \"malayalam\",\n",
    "    \"cy\": \"welsh\",\n",
    "    \"sk\": \"slovak\",\n",
    "    \"te\": \"telugu\",\n",
    "    \"fa\": \"persian\",\n",
    "    \"lv\": \"latvian\",\n",
    "    \"bn\": \"bengali\",\n",
    "    \"sr\": \"serbian\",\n",
    "    \"az\": \"azerbaijani\",\n",
    "    \"sl\": \"slovenian\",\n",
    "    \"kn\": \"kannada\",\n",
    "    \"et\": \"estonian\",\n",
    "    \"mk\": \"macedonian\",\n",
    "    \"br\": \"breton\",\n",
    "    \"eu\": \"basque\",\n",
    "    \"is\": \"icelandic\",\n",
    "    \"hy\": \"armenian\",\n",
    "    \"ne\": \"nepali\",\n",
    "    \"mn\": \"mongolian\",\n",
    "    \"bs\": \"bosnian\",\n",
    "    \"kk\": \"kazakh\",\n",
    "    \"sq\": \"albanian\",\n",
    "    \"sw\": \"swahili\",\n",
    "    \"gl\": \"galician\",\n",
    "    \"mr\": \"marathi\",\n",
    "    \"pa\": \"punjabi\",\n",
    "    \"si\": \"sinhala\",\n",
    "    \"km\": \"khmer\",\n",
    "    \"sn\": \"shona\",\n",
    "    \"yo\": \"yoruba\",\n",
    "    \"so\": \"somali\",\n",
    "    \"af\": \"afrikaans\",\n",
    "    \"oc\": \"occitan\",\n",
    "    \"ka\": \"georgian\",\n",
    "    \"be\": \"belarusian\",\n",
    "    \"tg\": \"tajik\",\n",
    "    \"sd\": \"sindhi\",\n",
    "    \"gu\": \"gujarati\",\n",
    "    \"am\": \"amharic\",\n",
    "    \"yi\": \"yiddish\",\n",
    "    \"lo\": \"lao\",\n",
    "    \"uz\": \"uzbek\",\n",
    "    \"fo\": \"faroese\",\n",
    "    \"ht\": \"haitian creole\",\n",
    "    \"ps\": \"pashto\",\n",
    "    \"tk\": \"turkmen\",\n",
    "    \"nn\": \"nynorsk\",\n",
    "    \"mt\": \"maltese\",\n",
    "    \"sa\": \"sanskrit\",\n",
    "    \"lb\": \"luxembourgish\",\n",
    "    \"my\": \"myanmar\",\n",
    "    \"bo\": \"tibetan\",\n",
    "    \"tl\": \"tagalog\",\n",
    "    \"mg\": \"malagasy\",\n",
    "    \"as\": \"assamese\",\n",
    "    \"tt\": \"tatar\",\n",
    "    \"haw\": \"hawaiian\",\n",
    "    \"ln\": \"lingala\",\n",
    "    \"ha\": \"hausa\",\n",
    "    \"ba\": \"bashkir\",\n",
    "    \"jw\": \"javanese\",\n",
    "    \"su\": \"sundanese\",\n",
    "    \"yue\": \"cantonese\",\n",
    "}\n",
    "\n",
    "# language code lookup by name, with a few language aliases\n",
    "TO_LANGUAGE_CODE = {\n",
    "    **{language: code for code, language in LANGUAGES.items()},\n",
    "    \"burmese\": \"my\",\n",
    "    \"valencian\": \"ca\",\n",
    "    \"flemish\": \"nl\",\n",
    "    \"haitian\": \"ht\",\n",
    "    \"letzeburgesch\": \"lb\",\n",
    "    \"pushto\": \"ps\",\n",
    "    \"panjabi\": \"pa\",\n",
    "    \"moldavian\": \"ro\",\n",
    "    \"moldovan\": \"ro\",\n",
    "    \"sinhalese\": \"si\",\n",
    "    \"castilian\": \"es\",\n",
    "}\n",
    "\n",
    "\n",
    "langs_to_iso = {\n",
    "    \"af\": \"afr\",\n",
    "    \"am\": \"amh\",\n",
    "    \"ar\": \"ara\",\n",
    "    \"as\": \"asm\",\n",
    "    \"az\": \"aze\",\n",
    "    \"ba\": \"bak\",\n",
    "    \"be\": \"bel\",\n",
    "    \"bg\": \"bul\",\n",
    "    \"bn\": \"ben\",\n",
    "    \"bo\": \"tib\",\n",
    "    \"br\": \"bre\",\n",
    "    \"bs\": \"bos\",\n",
    "    \"ca\": \"cat\",\n",
    "    \"cs\": \"cze\",\n",
    "    \"cy\": \"wel\",\n",
    "    \"da\": \"dan\",\n",
    "    \"de\": \"ger\",\n",
    "    \"el\": \"gre\",\n",
    "    \"en\": \"eng\",\n",
    "    \"es\": \"spa\",\n",
    "    \"et\": \"est\",\n",
    "    \"eu\": \"baq\",\n",
    "    \"fa\": \"per\",\n",
    "    \"fi\": \"fin\",\n",
    "    \"fo\": \"fao\",\n",
    "    \"fr\": \"fre\",\n",
    "    \"gl\": \"glg\",\n",
    "    \"gu\": \"guj\",\n",
    "    \"ha\": \"hau\",\n",
    "    \"haw\": \"haw\",\n",
    "    \"he\": \"heb\",\n",
    "    \"hi\": \"hin\",\n",
    "    \"hr\": \"hrv\",\n",
    "    \"ht\": \"hat\",\n",
    "    \"hu\": \"hun\",\n",
    "    \"hy\": \"arm\",\n",
    "    \"id\": \"ind\",\n",
    "    \"is\": \"ice\",\n",
    "    \"it\": \"ita\",\n",
    "    \"ja\": \"jpn\",\n",
    "    \"jw\": \"jav\",\n",
    "    \"ka\": \"geo\",\n",
    "    \"kk\": \"kaz\",\n",
    "    \"km\": \"khm\",\n",
    "    \"kn\": \"kan\",\n",
    "    \"ko\": \"kor\",\n",
    "    \"la\": \"lat\",\n",
    "    \"lb\": \"ltz\",\n",
    "    \"ln\": \"lin\",\n",
    "    \"lo\": \"lao\",\n",
    "    \"lt\": \"lit\",\n",
    "    \"lv\": \"lav\",\n",
    "    \"mg\": \"mlg\",\n",
    "    \"mi\": \"mao\",\n",
    "    \"mk\": \"mac\",\n",
    "    \"ml\": \"mal\",\n",
    "    \"mn\": \"mon\",\n",
    "    \"mr\": \"mar\",\n",
    "    \"ms\": \"may\",\n",
    "    \"mt\": \"mlt\",\n",
    "    \"my\": \"bur\",\n",
    "    \"ne\": \"nep\",\n",
    "    \"nl\": \"dut\",\n",
    "    \"nn\": \"nno\",\n",
    "    \"no\": \"nor\",\n",
    "    \"oc\": \"oci\",\n",
    "    \"pa\": \"pan\",\n",
    "    \"pl\": \"pol\",\n",
    "    \"ps\": \"pus\",\n",
    "    \"pt\": \"por\",\n",
    "    \"ro\": \"rum\",\n",
    "    \"ru\": \"rus\",\n",
    "    \"sa\": \"san\",\n",
    "    \"sd\": \"snd\",\n",
    "    \"si\": \"sin\",\n",
    "    \"sk\": \"slo\",\n",
    "    \"sl\": \"slv\",\n",
    "    \"sn\": \"sna\",\n",
    "    \"so\": \"som\",\n",
    "    \"sq\": \"alb\",\n",
    "    \"sr\": \"srp\",\n",
    "    \"su\": \"sun\",\n",
    "    \"sv\": \"swe\",\n",
    "    \"sw\": \"swa\",\n",
    "    \"ta\": \"tam\",\n",
    "    \"te\": \"tel\",\n",
    "    \"tg\": \"tgk\",\n",
    "    \"th\": \"tha\",\n",
    "    \"tk\": \"tuk\",\n",
    "    \"tl\": \"tgl\",\n",
    "    \"tr\": \"tur\",\n",
    "    \"tt\": \"tat\",\n",
    "    \"uk\": \"ukr\",\n",
    "    \"ur\": \"urd\",\n",
    "    \"uz\": \"uzb\",\n",
    "    \"vi\": \"vie\",\n",
    "    \"yi\": \"yid\",\n",
    "    \"yo\": \"yor\",\n",
    "    \"yue\": \"yue\",\n",
    "    \"zh\": \"chi\",\n",
    "}\n",
    "\n",
    "\n",
    "whisper_langs = sorted(LANGUAGES.keys()) + sorted(\n",
    "    [k.title() for k in TO_LANGUAGE_CODE.keys()]\n",
    ")\n",
    "\n",
    "\n",
    "def create_config(output_dir):\n",
    "    DOMAIN_TYPE = \"telephonic\"  # Can be meeting, telephonic, or general based on domain type of the audio file\n",
    "    CONFIG_FILE_NAME = f\"diar_infer_{DOMAIN_TYPE}.yaml\"\n",
    "    CONFIG_URL = f\"https://raw.githubusercontent.com/NVIDIA/NeMo/main/examples/speaker_tasks/diarization/conf/inference/{CONFIG_FILE_NAME}\"\n",
    "    MODEL_CONFIG = os.path.join(output_dir, CONFIG_FILE_NAME)\n",
    "    if not os.path.exists(MODEL_CONFIG):\n",
    "        MODEL_CONFIG = wget.download(CONFIG_URL, output_dir)\n",
    "\n",
    "    config = OmegaConf.load(MODEL_CONFIG)\n",
    "\n",
    "    data_dir = os.path.join(output_dir, \"data\")\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    meta = {\n",
    "        \"audio_filepath\": os.path.join(output_dir, \"mono_file.wav\"),\n",
    "        \"offset\": 0,\n",
    "        \"duration\": None,\n",
    "        \"label\": \"infer\",\n",
    "        \"text\": \"-\",\n",
    "        \"rttm_filepath\": None,\n",
    "        \"uem_filepath\": None,\n",
    "    }\n",
    "    with open(os.path.join(data_dir, \"input_manifest.json\"), \"w\") as fp:\n",
    "        json.dump(meta, fp)\n",
    "        fp.write(\"\\n\")\n",
    "\n",
    "    pretrained_vad = \"vad_multilingual_marblenet\"\n",
    "    pretrained_speaker_model = \"titanet_large\"\n",
    "    config.num_workers = 0  # Workaround for multiprocessing hanging with ipython issue\n",
    "    config.diarizer.manifest_filepath = os.path.join(data_dir, \"input_manifest.json\")\n",
    "    config.diarizer.out_dir = (\n",
    "        output_dir  # Directory to store intermediate files and prediction outputs\n",
    "    )\n",
    "\n",
    "    config.diarizer.speaker_embeddings.model_path = pretrained_speaker_model\n",
    "    config.diarizer.oracle_vad = (\n",
    "        False  # compute VAD provided with model_path to vad config\n",
    "    )\n",
    "    config.diarizer.clustering.parameters.oracle_num_speakers = False\n",
    "\n",
    "    # Here, we use our in-house pretrained NeMo VAD model\n",
    "    config.diarizer.vad.model_path = pretrained_vad\n",
    "    config.diarizer.vad.parameters.onset = 0.8\n",
    "    config.diarizer.vad.parameters.offset = 0.6\n",
    "    config.diarizer.vad.parameters.pad_offset = -0.05\n",
    "    config.diarizer.msdd_model.model_path = (\n",
    "        \"diar_msdd_telephonic\"  # Telephonic speaker diarization model\n",
    "    )\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_word_ts_anchor(s, e, option=\"start\"):\n",
    "    if option == \"end\":\n",
    "        return e\n",
    "    elif option == \"mid\":\n",
    "        return (s + e) / 2\n",
    "    return s\n",
    "\n",
    "def get_audio_extraction(input_file, output_file, start_min, end_min):\n",
    "    audio = AudioSegment.from_file(input_file, format=\"wav\")\n",
    "    start_min *= 60000\n",
    "    end_min *= 60000\n",
    "    ten_minutes = audio[start_min:end_min]  # Pydub uses milliseconds\n",
    "    ten_minutes.export(output_file, format=\"wav\")\n",
    "\n",
    "\n",
    "def get_words_speaker_mapping(wrd_ts, spk_ts, word_anchor_option=\"start\"):\n",
    "    s, e, sp = spk_ts[0]\n",
    "    wrd_pos, turn_idx = 0, 0\n",
    "    wrd_spk_mapping = []\n",
    "    for wrd_dict in wrd_ts:\n",
    "        ws, we, wrd = (\n",
    "            int(wrd_dict[\"start\"] * 1000),\n",
    "            int(wrd_dict[\"end\"] * 1000),\n",
    "            wrd_dict[\"text\"],\n",
    "        )\n",
    "        wrd_pos = get_word_ts_anchor(ws, we, word_anchor_option)\n",
    "        while wrd_pos > float(e):\n",
    "            turn_idx += 1\n",
    "            turn_idx = min(turn_idx, len(spk_ts) - 1)\n",
    "            s, e, sp = spk_ts[turn_idx]\n",
    "            if turn_idx == len(spk_ts) - 1:\n",
    "                e = get_word_ts_anchor(ws, we, option=\"end\")\n",
    "        wrd_spk_mapping.append(\n",
    "            {\"word\": wrd, \"start_time\": ws, \"end_time\": we, \"speaker\": sp}\n",
    "        )\n",
    "    return wrd_spk_mapping\n",
    "\n",
    "\n",
    "sentence_ending_punctuations = \".?!\"\n",
    "\n",
    "\n",
    "def get_first_word_idx_of_sentence(word_idx, word_list, speaker_list, max_words):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    left_idx = word_idx\n",
    "    while (\n",
    "        left_idx > 0\n",
    "        and word_idx - left_idx < max_words\n",
    "        and speaker_list[left_idx - 1] == speaker_list[left_idx]\n",
    "        and not is_word_sentence_end(left_idx - 1)\n",
    "    ):\n",
    "        left_idx -= 1\n",
    "\n",
    "    return left_idx if left_idx == 0 or is_word_sentence_end(left_idx - 1) else -1\n",
    "\n",
    "\n",
    "def get_last_word_idx_of_sentence(word_idx, word_list, max_words):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0 and word_list[x][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    right_idx = word_idx\n",
    "    while (\n",
    "        right_idx < len(word_list) - 1\n",
    "        and right_idx - word_idx < max_words\n",
    "        and not is_word_sentence_end(right_idx)\n",
    "    ):\n",
    "        right_idx += 1\n",
    "\n",
    "    return (\n",
    "        right_idx\n",
    "        if right_idx == len(word_list) - 1 or is_word_sentence_end(right_idx)\n",
    "        else -1\n",
    "    )\n",
    "\n",
    "\n",
    "def get_realigned_ws_mapping_with_punctuation(\n",
    "    word_speaker_mapping, max_words_in_sentence=50\n",
    "):\n",
    "    is_word_sentence_end = (\n",
    "        lambda x: x >= 0\n",
    "        and word_speaker_mapping[x][\"word\"][-1] in sentence_ending_punctuations\n",
    "    )\n",
    "    wsp_len = len(word_speaker_mapping)\n",
    "\n",
    "    words_list, speaker_list = [], []\n",
    "    for k, line_dict in enumerate(word_speaker_mapping):\n",
    "        word, speaker = line_dict[\"word\"], line_dict[\"speaker\"]\n",
    "        words_list.append(word)\n",
    "        speaker_list.append(speaker)\n",
    "\n",
    "    k = 0\n",
    "    while k < len(word_speaker_mapping):\n",
    "        line_dict = word_speaker_mapping[k]\n",
    "        if (\n",
    "            k < wsp_len - 1\n",
    "            and speaker_list[k] != speaker_list[k + 1]\n",
    "            and not is_word_sentence_end(k)\n",
    "        ):\n",
    "            left_idx = get_first_word_idx_of_sentence(\n",
    "                k, words_list, speaker_list, max_words_in_sentence\n",
    "            )\n",
    "            right_idx = (\n",
    "                get_last_word_idx_of_sentence(\n",
    "                    k, words_list, max_words_in_sentence - k + left_idx - 1\n",
    "                )\n",
    "                if left_idx > -1\n",
    "                else -1\n",
    "            )\n",
    "            if min(left_idx, right_idx) == -1:\n",
    "                k += 1\n",
    "                continue\n",
    "\n",
    "            spk_labels = speaker_list[left_idx : right_idx + 1]\n",
    "            mod_speaker = max(set(spk_labels), key=spk_labels.count)\n",
    "            if spk_labels.count(mod_speaker) < len(spk_labels) // 2:\n",
    "                k += 1\n",
    "                continue\n",
    "\n",
    "            speaker_list[left_idx : right_idx + 1] = [mod_speaker] * (\n",
    "                right_idx - left_idx + 1\n",
    "            )\n",
    "            k = right_idx\n",
    "\n",
    "        k += 1\n",
    "\n",
    "    k, realigned_list = 0, []\n",
    "    while k < len(word_speaker_mapping):\n",
    "        line_dict = word_speaker_mapping[k].copy()\n",
    "        line_dict[\"speaker\"] = speaker_list[k]\n",
    "        realigned_list.append(line_dict)\n",
    "        k += 1\n",
    "\n",
    "    return realigned_list\n",
    "\n",
    "\n",
    "def get_sentences_speaker_mapping(word_speaker_mapping, spk_ts):\n",
    "    sentence_checker = nltk.tokenize.PunktSentenceTokenizer().text_contains_sentbreak\n",
    "    s, e, spk = spk_ts[0]\n",
    "    prev_spk = spk\n",
    "\n",
    "    snts = []\n",
    "    snt = {\"speaker\": f\"Speaker {spk}\", \"start_time\": s, \"end_time\": e, \"text\": \"\"}\n",
    "\n",
    "    for wrd_dict in word_speaker_mapping:\n",
    "        wrd, spk = wrd_dict[\"word\"], wrd_dict[\"speaker\"]\n",
    "        s, e = wrd_dict[\"start_time\"], wrd_dict[\"end_time\"]\n",
    "        if spk != prev_spk or sentence_checker(snt[\"text\"] + \" \" + wrd):\n",
    "            snts.append(snt)\n",
    "            snt = {\n",
    "                \"speaker\": f\"Speaker {spk}\",\n",
    "                \"start_time\": s,\n",
    "                \"end_time\": e,\n",
    "                \"text\": \"\",\n",
    "            }\n",
    "        else:\n",
    "            snt[\"end_time\"] = e\n",
    "        snt[\"text\"] += wrd + \" \"\n",
    "        prev_spk = spk\n",
    "\n",
    "    snts.append(snt)\n",
    "    return snts\n",
    "\n",
    "\n",
    "def get_speaker_aware_transcript(sentences_speaker_mapping, f):\n",
    "    previous_speaker = sentences_speaker_mapping[0][\"speaker\"]\n",
    "    f.write(f\"{previous_speaker}: \")\n",
    "\n",
    "    for sentence_dict in sentences_speaker_mapping:\n",
    "        speaker = sentence_dict[\"speaker\"]\n",
    "        sentence = sentence_dict[\"text\"]\n",
    "\n",
    "        # If this speaker doesn't match the previous one, start a new paragraph\n",
    "        if speaker != previous_speaker:\n",
    "            f.write(f\"\\n\\n{speaker}: \")\n",
    "            previous_speaker = speaker\n",
    "\n",
    "        # No matter what, write the current sentence\n",
    "        f.write(sentence + \" \")\n",
    "\n",
    "\n",
    "def format_timestamp(\n",
    "    milliseconds: float, always_include_hours: bool = False, decimal_marker: str = \".\"\n",
    "):\n",
    "    assert milliseconds >= 0, \"non-negative timestamp expected\"\n",
    "\n",
    "    hours = milliseconds // 3_600_000\n",
    "    milliseconds -= hours * 3_600_000\n",
    "\n",
    "    minutes = milliseconds // 60_000\n",
    "    milliseconds -= minutes * 60_000\n",
    "\n",
    "    seconds = milliseconds // 1_000\n",
    "    milliseconds -= seconds * 1_000\n",
    "\n",
    "    hours_marker = f\"{hours:02d}:\" if always_include_hours or hours > 0 else \"\"\n",
    "    return (\n",
    "        f\"{hours_marker}{minutes:02d}:{seconds:02d}{decimal_marker}{milliseconds:03d}\"\n",
    "    )\n",
    "\n",
    "\n",
    "def write_srt(transcript, file):\n",
    "    \"\"\"\n",
    "    Write a transcript to a file in SRT format.\n",
    "\n",
    "    \"\"\"\n",
    "    for i, segment in enumerate(transcript, start=1):\n",
    "        # write srt lines\n",
    "        print(\n",
    "            f\"{i}\\n\"\n",
    "            f\"{format_timestamp(segment['start_time'], always_include_hours=True, decimal_marker=',')} --> \"\n",
    "            f\"{format_timestamp(segment['end_time'], always_include_hours=True, decimal_marker=',')}\\n\"\n",
    "            f\"{segment['speaker']}: {segment['text'].strip().replace('-->', '->')}\\n\",\n",
    "            file=file,\n",
    "            flush=True,\n",
    "        )\n",
    "\n",
    "\n",
    "def find_numeral_symbol_tokens(tokenizer):\n",
    "    numeral_symbol_tokens = [\n",
    "        -1,\n",
    "    ]\n",
    "    for token, token_id in tokenizer.get_vocab().items():\n",
    "        has_numeral_symbol = any(c in \"0123456789%$£\" for c in token)\n",
    "        if has_numeral_symbol:\n",
    "            numeral_symbol_tokens.append(token_id)\n",
    "    return numeral_symbol_tokens\n",
    "\n",
    "\n",
    "def _get_next_start_timestamp(word_timestamps, current_word_index, final_timestamp):\n",
    "    # if current word is the last word\n",
    "    if current_word_index == len(word_timestamps) - 1:\n",
    "        return word_timestamps[current_word_index][\"start\"]\n",
    "\n",
    "    next_word_index = current_word_index + 1\n",
    "    while current_word_index < len(word_timestamps) - 1:\n",
    "        if word_timestamps[next_word_index].get(\"start\") is None:\n",
    "            # if next word doesn't have a start timestamp\n",
    "            # merge it with the current word and delete it\n",
    "            word_timestamps[current_word_index][\"word\"] += (\n",
    "                \" \" + word_timestamps[next_word_index][\"word\"]\n",
    "            )\n",
    "\n",
    "            word_timestamps[next_word_index][\"word\"] = None\n",
    "            next_word_index += 1\n",
    "            if next_word_index == len(word_timestamps):\n",
    "                return final_timestamp\n",
    "\n",
    "        else:\n",
    "            return word_timestamps[next_word_index][\"start\"]\n",
    "\n",
    "\n",
    "def filter_missing_timestamps(\n",
    "    word_timestamps, initial_timestamp=0, final_timestamp=None\n",
    "):\n",
    "    # handle the first and last word\n",
    "    if word_timestamps[0].get(\"start\") is None:\n",
    "        word_timestamps[0][\"start\"] = (\n",
    "            initial_timestamp if initial_timestamp is not None else 0\n",
    "        )\n",
    "        word_timestamps[0][\"end\"] = _get_next_start_timestamp(\n",
    "            word_timestamps, 0, final_timestamp\n",
    "        )\n",
    "\n",
    "    result = [\n",
    "        word_timestamps[0],\n",
    "    ]\n",
    "\n",
    "    for i, ws in enumerate(word_timestamps[1:], start=1):\n",
    "        # if ws doesn't have a start and end\n",
    "        # use the previous end as start and next start as end\n",
    "        if ws.get(\"start\") is None and ws.get(\"word\") is not None:\n",
    "            ws[\"start\"] = word_timestamps[i - 1][\"end\"]\n",
    "            ws[\"end\"] = _get_next_start_timestamp(word_timestamps, i, final_timestamp)\n",
    "\n",
    "        if ws[\"word\"] is not None:\n",
    "            result.append(ws)\n",
    "    return result\n",
    "\n",
    "\n",
    "def cleanup(path: str):\n",
    "    \"\"\"path could either be relative or absolute.\"\"\"\n",
    "    # check if file or directory exists\n",
    "    if os.path.isfile(path) or os.path.islink(path):\n",
    "        # remove file\n",
    "        os.remove(path)\n",
    "    elif os.path.isdir(path):\n",
    "        # remove directory and all its content\n",
    "        shutil.rmtree(path)\n",
    "    else:\n",
    "        raise ValueError(\"Path {} is not a file or dir.\".format(path))\n",
    "\n",
    "\n",
    "def process_language_arg(language: str, model_name: str):\n",
    "    \"\"\"\n",
    "    Process the language argument to make sure it's valid and convert language names to language codes.\n",
    "    \"\"\"\n",
    "    if language is not None:\n",
    "        language = language.lower()\n",
    "    if language not in LANGUAGES:\n",
    "        if language in TO_LANGUAGE_CODE:\n",
    "            language = TO_LANGUAGE_CODE[language]\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported language: {language}\")\n",
    "\n",
    "    if model_name.endswith(\".en\") and language != \"en\":\n",
    "        if language is not None:\n",
    "            logging.warning(\n",
    "                f\"{model_name} is an English-only model but received '{language}'; using English instead.\"\n",
    "            )\n",
    "        language = \"en\"\n",
    "    return language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_fast = True\n",
    "is_configured = True\n",
    "enable_stemming = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "# print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "# print(segments)\n",
    "# for segment in segments:\n",
    "#     print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd2803776d04b978d8fa984f05f50fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:   3%|3         | 105M/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/655f2075d3934dc40213a799/982bcaa78dd99dc42935ee11f021a876aaf08c11171817ad8a4d6bc1c881b3a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250223T135840Z&X-Amz-Expires=900&X-Amz-Signature=0ad5c7d266c000161158cbcf88d7545d1f404130670eb15fe4f51f1519add7e7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=66c6007877ad31f2c074a29a&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.bin%3B+filename%3D%22model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1740322720&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDMyMjcyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTVmMjA3NWQzOTM0ZGM0MDIxM2E3OTkvOTgyYmNhYTc4ZGQ5OWRjNDI5MzVlZTExZjAyMWE4NzZhYWYwOGMxMTE3MTgxN2FkOGE0ZDZiYzFjODgxYjNhNSoifV19&Signature=kGAr58frudA5xPytz1r4%7EkB9o78jtIdqgnfkffAa12-AoNUguCmQHeSg1Hsrd5Bk6OBKNhPrlWRzLp7BN2gQ7dSPruudnmO%7E20SYHHyuca36J2LoI71bZ%7EzHzo8sH81iEKaMRJ1jOCIaHshGJ-Dle8V9DMXXr20DTVnqVx8d11caDbMn9RTCDMMob2Oc9Z%7EtjvsO3tIFWl4Ego-mqxqvntJLrjwGsleZ%7EG7kPP8TdqW%7Eirx1KslRy5-P3L3yVcYos2SolD04%7E9aJvgC67fSuF4ZK9RcplTtI6DB1L5bEhFoeUrAPsN9FGkBf8JRvqEv6KnC%7EfQA4IxRAZf4A1a1FGA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbc0d9925e24fb081e2bcd80ef7d758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:  15%|#4        | 461M/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/655f2075d3934dc40213a799/982bcaa78dd99dc42935ee11f021a876aaf08c11171817ad8a4d6bc1c881b3a5?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250223%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250223T135840Z&X-Amz-Expires=900&X-Amz-Signature=0ad5c7d266c000161158cbcf88d7545d1f404130670eb15fe4f51f1519add7e7&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=66c6007877ad31f2c074a29a&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.bin%3B+filename%3D%22model.bin%22%3B&response-content-type=application%2Foctet-stream&x-id=GetObject&Expires=1740322720&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MDMyMjcyMH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NTVmMjA3NWQzOTM0ZGM0MDIxM2E3OTkvOTgyYmNhYTc4ZGQ5OWRjNDI5MzVlZTExZjAyMWE4NzZhYWYwOGMxMTE3MTgxN2FkOGE0ZDZiYzFjODgxYjNhNSoifV19&Signature=kGAr58frudA5xPytz1r4%7EkB9o78jtIdqgnfkffAa12-AoNUguCmQHeSg1Hsrd5Bk6OBKNhPrlWRzLp7BN2gQ7dSPruudnmO%7E20SYHHyuca36J2LoI71bZ%7EzHzo8sH81iEKaMRJ1jOCIaHshGJ-Dle8V9DMXXr20DTVnqVx8d11caDbMn9RTCDMMob2Oc9Z%7EtjvsO3tIFWl4Ego-mqxqvntJLrjwGsleZ%7EG7kPP8TdqW%7Eirx1KslRy5-P3L3yVcYos2SolD04%7E9aJvgC67fSuF4ZK9RcplTtI6DB1L5bEhFoeUrAPsN9FGkBf8JRvqEv6KnC%7EfQA4IxRAZf4A1a1FGA__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902ea67fe4a544858b7748d773cb131c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.bin:  15%|#5        | 472M/3.09G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# num_list = [\"1554\",\"1713\",\"1731\",\"1738\",\"1833\",\"1944\"]\n",
    "num_list = [\"1554\"]\n",
    "\n",
    "model_name = \"large-v3\"\n",
    "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device_type)\n",
    "\n",
    "compute_type = \"float16\"\n",
    "suppress_numerals = True\n",
    "whisper_model = faster_whisper.WhisperModel(\n",
    "    model_name, device=device_type, compute_type=compute_type\n",
    ")\n",
    "whisper_pipeline = faster_whisper.BatchedInferencePipeline(whisper_model)\n",
    "suppress_tokens = (\n",
    "    find_numeral_symbol_tokens(whisper_model.hf_tokenizer)\n",
    "    if suppress_numerals\n",
    "    else [-1]\n",
    ")\n",
    "language = None  # autodetect language\n",
    "batch_size = 8\n",
    "is_fast = True\n",
    "config_path = \"\"\n",
    "if is_configured:\n",
    "    config_path = \"C\"\n",
    "if model_name == \"large-v3\" and is_fast:\n",
    "    path_name = \"largeV3F\"\n",
    "elif model_name == \"large-v3\":\n",
    "    path_name = \"largeV3C\"\n",
    "elif model_name == \"large-v3\":\n",
    "    path_name = \"largeV3\"\n",
    "elif model_name == \"base\":\n",
    "    path_name = \"base\"\n",
    "\n",
    "for num in num_list:\n",
    "    #audio_path = f'./Dataset/Audio/{num}.wav'\n",
    "    audio_path = \"first_1_minutes.wav\"\n",
    "\n",
    "    if enable_stemming:\n",
    "        # Isolate vocals from the rest of the audio\n",
    "        return_code = os.system(\n",
    "            f'python -m demucs.separate -n htdemucs --two-stems=vocals \"{audio_path}\" -o \"temp_outputs\" --device \"{device_type}\"'\n",
    "        )\n",
    "        if return_code != 0:\n",
    "            print(\"Source splitting failed, using original audio file.\")\n",
    "            vocal_target = audio_path\n",
    "        else:\n",
    "            vocal_target = os.path.join(\n",
    "                \"temp_outputs\",\n",
    "                \"htdemucs\",\n",
    "                os.path.splitext(os.path.basename(audio_path))[0],\n",
    "                \"vocals.wav\",\n",
    "            )\n",
    "    else:\n",
    "        vocal_target = audio_path\n",
    "\n",
    "    audio_waveform = faster_whisper.decode_audio(vocal_target)\n",
    "    # if sample_rate != 16000:\n",
    "    #     print(f\"Resampling from {sample_rate} Hz to 16000 Hz...\")\n",
    "    #     speech, sample_rate = librosa.load(audio_file, sr=None)\n",
    "    #     speech = librosa.resample(speech, orig_sr=sample_rate, target_sr=16000)\n",
    "    #     sample_rate = 16000\n",
    "    #     sf.write(audio_file, speech, sample_rate)\n",
    "\n",
    "    if is_configured:\n",
    "        transcript_segments, info = whisper_pipeline.transcribe(\n",
    "            audio_waveform,\n",
    "            language=language,\n",
    "            suppress_tokens=suppress_tokens,\n",
    "            beam_size=1,\n",
    "            temperature=0.0,\n",
    "            without_timestamps=False,\n",
    "            vad_filter=True,\n",
    "        )\n",
    "    else:\n",
    "        transcript_segments, info = whisper_pipeline.transcribe(\n",
    "            audio_waveform,\n",
    "            language=language,\n",
    "            suppress_tokens=suppress_tokens,\n",
    "            without_timestamps=False,\n",
    "            vad_filter=True,\n",
    "        )\n",
    "    result = []\n",
    "    for seg in transcript_segments:\n",
    "        result.append({\"text\": seg.text,\"start\":seg.start, \"end\": seg.end})\n",
    "        print(str(seg.start) + \"-\" + str(seg.end) + \": \"+ seg.text)\n",
    "        \n",
    "\n",
    "        \n",
    "    # full_transcript = \"\".join(segment.text for segment in transcript_segments)\n",
    "    # file_path = f\"./output/{path_name}{config_path}_{num}.txt\"\n",
    "    # output_path = f\"./output/{path_name}{config_path}_{num}_L.txt\"\n",
    "    # with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "    #     file.write(full_transcript.lower())\n",
    "    # utils.process_text(file_path,output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del whisper_model, whisper_pipeline\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/home/arsalan77x/Whisper/venv/lib/python3.12/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/arsalan77x/Whisper/venv/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at /pytorch/aten/src/ATen/native/ReduceOps.cpp:1831.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker SPEAKER_01:  So I'm just gonna be asking you to do some talking.\n",
      "Speaker SPEAKER_00:  Okay.\n",
      "Speaker SPEAKER_01:  So how do you think your speeches these days?\n",
      "Speaker SPEAKER_00:  It's good, but...\n",
      "Speaker SPEAKER_00:  will be better.\n",
      "Speaker SPEAKER_00:  I can...\n",
      "Speaker SPEAKER_00:  little... I can read a little bit...\n",
      "Speaker SPEAKER_00:  I have trouble with uh...\n",
      "Speaker SPEAKER_00:  and then then...\n",
      "Speaker SPEAKER_00:  and then...\n",
      "Speaker SPEAKER_00:  hold that.\n",
      "Speaker SPEAKER_01:  Do you remember when you had your stroke?\n",
      "Speaker SPEAKER_00:  Yeah.\n",
      "Speaker SPEAKER_01:  Could you tell me about it?\n",
      "Speaker SPEAKER_00:  Oh gosh.\n",
      "Speaker SPEAKER_00:  Well, I got...\n",
      "Speaker SPEAKER_00:  I got up to check the...\n"
     ]
    }
   ],
   "source": [
    "import whisperx\n",
    "import gc\n",
    "device = \"cuda\"\n",
    "audio_path = \"first_1_minutes.wav\"\n",
    "audio = whisperx.load_audio(audio_path)\n",
    "\n",
    "# 2. Align whisper output\n",
    "model_a, metadata = whisperx.load_align_model(language_code=\"en\", device=device)\n",
    "result = whisperx.align(result, model_a, metadata, audio, device, return_char_alignments=False)\n",
    "\n",
    "# 3. Assign speaker labels\n",
    "diarize_model = whisperx.DiarizationPipeline(use_auth_token=\"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\", device=device)\n",
    "diarize_segments = diarize_model(audio, num_speakers=2)  # Or adjust min/max speakers\n",
    "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "\n",
    "\n",
    "S0 = \"\"\n",
    "S1 = \"\"\n",
    "# 4. Print speaker names with their utterances\n",
    "for segment in result[\"segments\"]:\n",
    "    speaker_id = segment[\"speaker\"]\n",
    "    utterance = segment[\"text\"]\n",
    "    if speaker_id == \"SPEAKER_00\":\n",
    "        S0 += utterance + \" \"\n",
    "    else:\n",
    "        S1 += utterance + \" \"\n",
    "    print(f\"Speaker {speaker_id}: {utterance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmodel_a\u001b[49m\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_a' is not defined"
     ]
    }
   ],
   "source": [
    "del model_a, diarize_model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wav2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soʊ aɪm bɪskɪn ʌ bi æskɪŋ ju sɪtisɪn hɑki ʊkɪsɛw hæv ju θɪŋk jʊ spit͡ʃɪz ðis deɪɪts ɡɛ beɪ ʌm æ wu bi bɛtɚ m  aɪ kʌn  lɪtʌl aɪ kʌn bɹid ʌ lɪtolbʌ   aɪ hæv tɹʌvʌl wɪd ʌ  ʌntnʌbæ   ju ɚba jɚ ɹɛdi hæd ɹistɹʌ j hæ ænd kʊd ju tɛl ju bɑtɪoʊwʌnwɛl aɪ ɡɑ m aɪ ɡɑtʌ tɪ t͡ʃɛk dʌ wɑndɚi æn m aɪ ɡɑt ʌbaʊ ðeɪɹ m ɪn ðʌ dɔɹʌweɪ ɛvðʌ keʃʌn æn aɪ doʊ ɹimɛmbɚ æ aɪ ɡoʊ tu veɪ ˌʌndɚbɛlʌnæ sɔl aɪ kʌn ɹɪmɛmbɚ n ʌn wʌt ʌbaʊt jʊ fɹɚ spɛnɚei æftɚ ð stɹʌp aɪ wʌz skɛɹn sowʌt baʊt jʊɹ ɹɪkʌvɚi hwʌt kaɪndz ʌv θɪŋz hæv ju dʌn tɪ t͡ʃɹaɪtɪɡ æt bɛtɚ sɪn ɚstɹʌæm aɪ m ɛksɚsaɪz ʌ aɪp taɪm   ʌ wik nd m aɪ hæv spt͡ʃ ʌn ʌm spɚn kɚsmʌspɹɪk ʌ stɑɹtɪŋ ʌk nɛkst  tu tusteɪwɛn wɛnsdɛɡɔ ɪn weɪk æm ʌn ʌʌ ʌ ʌs  dɑktɚt ʌpɪ ʌn nɔ tʌɛw æʊt taɪ n  æksɚsˌaɪzɪŋ aɪ ðɛɹ ɛni ʌðɚ t͡ʃeɪnd͡ʒɪz ɪn jɚ deɪl deɪlˌaɪɑ wˌaɪ aɪ aɪ keɪŋ wɚk ʌnaɪ wɑtʃ mʌ ɡɹæm sʌɪn  n ætsɛaɪ ʌn d͡ɹaɪv naʊ ɪʌn θki ʌkhæsɛlaɪmn kʌn æsk jɪ ju ju ʌ kʌbliθŋ s  tɔki ʌ kʌn æ ænd tɑkʌz bæd ʒɪsz jukæm ʌbaʊt it͡ʃ wˌʌn kʌz ju leɪtɚ dɛlʌ ɹɪkɹˌɪt͡ʃ ʌk ɪ ʌ sɛwθɪŋkɪŋ bæk kæn ju tɛl m jʊɚ stɔɹi ʌbaʊt sʌmθɪŋ ɪn wɚk  ɪ ɑt hæbʌn tɪ ju ɪn jʊɹ laɪf æ ɛk bi hæpiju ɚ stæd  k bi ʌ  wɪn j ɛkd ɑɹmɚ ɹiʌndli  kʃ ʌ         aɪ doʊnt tɔk ʌbɑt ʌn dʌstɪŋ  æd  aɪ aɪ doʊ wʌn tɔk ʌbaʊt dæt wʌn  nɛ  n ju æ ʌvɪɡ kwɛt͡ʃʌn æn pɹaɪ hu maɪ dɑtɚ hævɪn twɪnz naʊ ænd  m meɪ  sɪs sɛvʌnt  ʌ steɪŋ wɪθɚ  wns  wɛn ʃi hæz ðʌ beɪɹisʌn ɛw baʊ ɚn wɪtʌwˌawl  ʌm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "#https://github.com/huggingface/transformers/blob/main/examples/research_projects/wav2vec2/FINE_TUNE_XLSR_WAV2VEC2.md\n",
    "#https://github.com/crazycloud/mispronunciation-detection-diagnosis-wav2vec2-and-llm/blob/main/notebooks/mispronunciation-detection.ipynb\n",
    "#https://github.com/NeuralVox/OpenPhonemizer\n",
    "pipe = pipeline(model=\"mrrubino/wav2vec2-large-xlsr-53-l2-arctic-phoneme\")\n",
    "transcription = pipe(\"1554_chunks/chunk_1.wav\")[\"text\"]\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2d26f4bb25142b8aa839c7a07fc2b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcb28ae11414d2d8fd6f0582b6ed963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/294 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc828559027a479d9b23a352aa4d8458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/410 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c36506bf9e545869693628da52370b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ce5c6c870f4ed581892305fea16a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/309 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8310520a3a9141eea99f740e95412f99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  20%|#9        | 252M/1.26G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Wav2Vec2Processor, Wav2Vec2ForCTC\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "# Load model and processor\n",
    "model_name = \"vitouphy/wav2vec2-xls-r-300m-phoneme\"\n",
    "processor = Wav2Vec2Processor.from_pretrained(model_name)\n",
    "model = Wav2Vec2ForCTC.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'soʊaɪm ʤɪs gɪnɪ biæs kɪŋju tɪ dusəm tɑ kiŋoʊ keɪsoʊ haʊɾiuθɪŋ k jɝs pi ʧɪɾɪz ðiz deɪzhɪ t s gʊ bɛ əmw l bi bɛɾɝəmaɪ kɪnhlɪɾl  aɪ k n b ɹi ð əlɪɾ l bɛ ɑmɑmaɪhæv ʧɹə b lwɪθə inɛnθəhɑvɑdɪjuɹɪmɛm bɝwɛn juhæ d jɝs t ɹoʊ kjæ h əmkɪ d u tɛl miɪ baʊɾɪ oʊ kɑʃɪ wɛl aɪ gɑ əm  aɪgɑɾə  p tu ʧɛ ðə lɑn ʤɝi æn   m  aɪ  gɑɾə baʊ  ðeɪɝ  əm ɪnðɪ dɑɹ weɪəvəðɪ kɪ ʧɪn ænaɪ doʊn ɹimɛm bɝ aɪ  goʊ tuviɪn dɝ bɪl ɛnðæ sɑlaɪ kɪn ɹɝmɛm bɝəm wəɾɪ baʊ jɝfɝs mɛmɝiɪz æf tɝðɪs d ɹə kaɪwʊs kɛɝ djæəmə keɪsoʊhwəɾɪ baʊ jɝɹɝ kəvɝi wə kaɪn zɪvθɪŋzhɪv ju dən tɪ t ɹaɪɾɪ gɛ bɛɾɝsɪn s jus t ɹoʊ p thəm aɪmhəmɛ  sɝsaɪz əmffaɪv taɪm zəhmnəwi kæn dəm  aɪhæv s pi ʧəm   əms p ɹɪŋ  k ɹɪs mɪs b ɹeɪ kə  s tɑɹɾiŋ ə pnnɛ k s tmtuz tuz deɪwɪn wɪn z deɪ ðfɑləɪŋwi khæn dɑɑaɪɾʊ ələnoʊhə t sɪ aɪhdɑ tɝzə pɔɪn mɪn swəhɪn t ɹɛəzhsoʊ   saɪɾɪ ɑf ɛ k sɝsaɪziŋɑɹðɛɹ ɛniəðɝ ʧin ʤɪzɪn jɝ deɪɾɪ deɪwaɪfoʊaɪ   aɪaɪ kin wɝ khaɪwɑ ʧmaɪ g ɹæn sənɛnɛnðæ sɪ h aɪ kɪn ʤaɪv naʊ ɑjɪ sɛllə  sə g ɹii  oʊ keɪssoʊnaʊm gɪnə æs k juɾɪ ʤuɪ kə p ləðɝθɪŋz wɪθ tɑ kiŋ oʊ keɪmɪ æn tɑ kɪz mə ʧɪz u kænɪ baʊ i ʧwən kɪz wɪɹɪliɪn tɹɪs tɪɾɪn lɪŋ g wɪ ʧoʊ keɪ m ssoʊ θɪŋ kɪŋ bæ kkkɪn ju tɛl miəvs tɑɹi ə baʊ səmθɪŋɪm pɑɹ nn ðæ hæ pɪn tjuɪn jɝlaɪf  əm ɪ kɪ bihæ piiɝɹsæ dɪ ɪ kɪ bi mhəməniɹeɪ khɛdə ɑɹ mɑɹisɪn t liɪb ɹi p ɝəvɑɑhɑhaʊkɑʃaɪ doʊn tɑ kə baʊ əm dəsθin əhaɪ aɪ aɪ doʊn wənə tɑ kə baʊ ðæ wən ihɪhəoʊnaʊnoʊɪ sɪ bɪ k wɛʃɪn kaɪnəvvɝɑ dihumaɪ dɑɾɝɪzhæviŋ t wɪn z naʊəməə meɪmeɪhɑʤuhəfɛsɪ k səvənsɛvənθaɪms tiŋwɪθhɝ əmwɪn  s əwɛnʃihhhæzðə beɪɹizɪn shɛl paʊ fɝəlɪɾl waɪlaɪəmhɝz'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the model\n",
    "pipe = pipeline(model=\"vitouphy/wav2vec2-xls-r-300m-timit-phoneme\")\n",
    "\n",
    "# Process raw audio\n",
    "output = pipe(\"1554_chunks/chunk_1.wav\", chunk_length_s=10, stride_length_s=(4, 2))\n",
    "\n",
    "# Print the transcription\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phonemize Whisper result before alignment\n",
    "# use whiper phonemized data for training n-gram?!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import batchalign as ba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4166d15fd316411c876a3d9f899752c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/4.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fbab4993be14f9282cadd0d502f0481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d2bbfd07f94082b0e62661abd80ad4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058cbb35104244cbb701d3d453e0af79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e41f51c168242bea9af36610d7ea8bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04345743fc5847e0972492cb6c97aac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc4f2a9c49d467b9adac1d54e3ce642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94796f02212f4e0f9a52c4b24933d1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bef75bad7822483fbe7f1e0ee4169509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.28k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0860d0ea36a24472ad18c8c3cee05736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/6.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m so i\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mm just gonna be asking you to do some talking. okay. so how do you think your speech is these days? it\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms good, but... it will be better. i can... little... i can read a little, but... i have trouble with and and the and all that. do you remember when you had your stroke? yeah. could you tell me about it? oh gosh. well i got i got up to check the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m \u001b[43mba\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBatchalignPipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43masr,morphosyntax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_speakers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m doc \u001b[38;5;241m=\u001b[39m ba\u001b[38;5;241m.\u001b[39mDocument\u001b[38;5;241m.\u001b[39mnew(media_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst_1_minutes.wav\u001b[39m\u001b[38;5;124m\"\u001b[39m, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meng\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m doc \u001b[38;5;241m=\u001b[39m nlp(doc) \u001b[38;5;66;03m# this is equivalent to nlp(\"audio.mp3\"), we will make the initial doc for you\u001b[39;00m\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/batchalign/pipelines/pipeline.py:60\u001b[0m, in \u001b[0;36mBatchalignPipeline.new\u001b[0;34m(tasks, lang, num_speakers, **arg_overrides)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create the pipeline.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;124;03m    The pipeline to run.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mbatchalign\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipelines\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdispatch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dispatch_pipeline\n\u001b[0;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_speakers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_speakers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marg_overrides\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/batchalign/pipelines/dispatch.py:106\u001b[0m, in \u001b[0;36mdispatch_pipeline\u001b[0;34m(pkg_str, lang, num_speakers, **arg_overrides)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# decode and initialize\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisper\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 106\u001b[0m     engines\u001b[38;5;241m.\u001b[39mappend(\u001b[43mWhisperEngine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhisperx\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    108\u001b[0m     engines\u001b[38;5;241m.\u001b[39mappend(WhisperXEngine(lang\u001b[38;5;241m=\u001b[39mlang))\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/batchalign/pipelines/asr/whisper.py:42\u001b[0m, in \u001b[0;36mWhisperEngine.__init__\u001b[0;34m(self, model, lang)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreek\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m language\u001b[38;5;241m.\u001b[39mlower():\n\u001b[1;32m     40\u001b[0m     language \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGreek\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__whisper \u001b[38;5;241m=\u001b[39m \u001b[43mWhisperASRModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__lang \u001b[38;5;241m=\u001b[39m lang\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolve(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutterance\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__lang) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/batchalign/models/whisper/infer_asr.py:71\u001b[0m, in \u001b[0;36mWhisperASRModel.__init__\u001b[0;34m(self, model, base, language, target_sample_rate)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config \u001b[38;5;241m=\u001b[39m GenerationConfig\u001b[38;5;241m.\u001b[39mfrom_pretrained(base)\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__config\u001b[38;5;241m.\u001b[39mno_repeat_ngram_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m4\u001b[39m\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautomatic-speech-recognition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWhisperTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk_length_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride_length_s\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_timestamps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mword\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m L\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone, initalizing processor and config...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     82\u001b[0m processor \u001b[38;5;241m=\u001b[39m WhisperProcessor\u001b[38;5;241m.\u001b[39mfrom_pretrained(base)\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/transformers/pipelines/__init__.py:940\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m framework \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    939\u001b[0m     model_classes \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m: targeted_task[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m]}\n\u001b[0;32m--> 940\u001b[0m     framework, model \u001b[38;5;241m=\u001b[39m \u001b[43minfer_framework_load_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_classes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    950\u001b[0m model_config \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\n\u001b[1;32m    951\u001b[0m hub_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39m_commit_hash\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/transformers/pipelines/base.py:289\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[0;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[1;32m    283\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrying to load the model with Tensorflow.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    286\u001b[0m     )\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 289\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    291\u001b[0m         model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    570\u001b[0m )\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/transformers/modeling_utils.py:3805\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3803\u001b[0m         \u001b[38;5;66;03m# This repo has no safetensors file of any kind, we switch to PyTorch.\u001b[39;00m\n\u001b[1;32m   3804\u001b[0m         filename \u001b[38;5;241m=\u001b[39m _add_variant(WEIGHTS_NAME, variant)\n\u001b[0;32m-> 3805\u001b[0m         resolved_archive_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcached_file_kwargs\u001b[49m\n\u001b[1;32m   3807\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m filename \u001b[38;5;241m==\u001b[39m _add_variant(WEIGHTS_NAME, variant):\n\u001b[1;32m   3809\u001b[0m     \u001b[38;5;66;03m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     resolved_archive_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[1;32m   3811\u001b[0m         pretrained_model_name_or_path,\n\u001b[1;32m   3812\u001b[0m         _add_variant(WEIGHTS_INDEX_NAME, variant),\n\u001b[1;32m   3813\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcached_file_kwargs,\n\u001b[1;32m   3814\u001b[0m     )\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/transformers/utils/hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m user_agent \u001b[38;5;241m=\u001b[39m http_user_agent(user_agent)\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    418\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m _get_cache_file_to_return(path_or_repo_id, full_filename, cache_dir, revision)\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _hf_hub_download_to_local_dir(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;66;03m# Destination\u001b[39;00m\n\u001b[1;32m    842\u001b[0m         local_dir\u001b[38;5;241m=\u001b[39mlocal_dir,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    857\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    858\u001b[0m     )\n\u001b[1;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1009\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1007\u001b[0m Path(lock_path)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mmkdir(parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[0;32m-> 1009\u001b[0m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.incomplete\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(pointer_path):\n\u001b[1;32m   1020\u001b[0m         _create_symlink(blob_path, pointer_path, new_blob\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1543\u001b[0m, in \u001b[0;36m_download_to_tmp_and_move\u001b[0;34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download)\u001b[0m\n\u001b[1;32m   1540\u001b[0m         _check_disk_space(expected_size, incomplete_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m   1541\u001b[0m         _check_disk_space(expected_size, destination_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[0;32m-> 1543\u001b[0m     \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1546\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1552\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1553\u001b[0m _chmod_and_move(incomplete_path, destination_path)\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:452\u001b[0m, in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[0m\n\u001b[1;32m    450\u001b[0m new_resume_size \u001b[38;5;241m=\u001b[39m resume_size\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 452\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconstants\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n\u001b[1;32m    454\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/urllib3/response.py:1066\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1066\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1068\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1069\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/urllib3/response.py:955\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m amt:\n\u001b[1;32m    953\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mget(amt)\n\u001b[0;32m--> 955\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    957\u001b[0m flush_decoder \u001b[38;5;241m=\u001b[39m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n\u001b[1;32m    959\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/urllib3/response.py:879\u001b[0m, in \u001b[0;36mHTTPResponse._raw_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    876\u001b[0m fp_closed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclosed\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_error_catcher():\n\u001b[0;32m--> 879\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    888\u001b[0m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    889\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Whisper/venv/lib/python3.12/site-packages/urllib3/response.py:862\u001b[0m, in \u001b[0;36mHTTPResponse._fp_read\u001b[0;34m(self, amt, read1)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1(amt) \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread1()\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/usr/lib/python3.12/http/client.py:479\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength:\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;66;03m# clip the read to the \"end of response\"\u001b[39;00m\n\u001b[1;32m    478\u001b[0m     amt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlength\n\u001b[0;32m--> 479\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.12/socket.py:707\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 707\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1252\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1248\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1249\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1251\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.12/ssl.py:1104\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1104\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1105\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1106\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "text = \" so i'm just gonna be asking you to do some talking. okay. so how do you think your speech is these days? it's good, but... it will be better. i can... little... i can read a little, but... i have trouble with and and the and all that. do you remember when you had your stroke? yeah. could you tell me about it? oh gosh. well i got i got up to check the\"\n",
    "nlp = ba.BatchalignPipeline.new(\"asr,morphosyntax\", lang=\"eng\", num_speakers=2)\n",
    "doc = ba.Document.new(media_path=\"first_1_minutes.wav\", lang=\"eng\")\n",
    "doc = nlp(doc) # this is equivalent to nlp(\"audio.mp3\"), we will make the initial doc for you\n",
    "\n",
    "first_word_pos = doc[0][0].morphology\n",
    "first_word_time = doc[0][0].time\n",
    "first_utterance_time = doc[0].alignment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
