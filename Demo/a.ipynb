{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96f4a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>Performing voice activity detection using Pyannote...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.5.0.post0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../venv/lib/python3.12/site-packages/whisperx/assets/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 3.3.2. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.5.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arsalan77x/Whisper/venv/lib/python3.12/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.\n",
      "It can be re-enabled by calling\n",
      "   >>> import torch\n",
      "   >>> torch.backends.cuda.matmul.allow_tf32 = True\n",
      "   >>> torch.backends.cudnn.allow_tf32 = True\n",
      "See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.\n",
      "\n",
      "  warnings.warn(\n",
      "/home/arsalan77x/Whisper/venv/lib/python3.12/site-packages/pyannote/audio/models/blocks/pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at ../aten/src/ATen/native/ReduceOps.cpp:1823.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    }
   ],
   "source": [
    "import whisperx, gc, torch\n",
    "\n",
    "device       = \"cuda\"\n",
    "audio_file   = \"1.wav\"\n",
    "batch_size   = 2\n",
    "compute_type = \"float16\"       # must match what you chose during conversion\n",
    "model_path   = \"/home/arsalan77x/Whisper/chatwhisper-en-ct2\"   # << your folder\n",
    "\n",
    "model = whisperx.load_model(\n",
    "    model_path,\n",
    "    device=device,\n",
    "    language=\"en\",             # set explicitly if your model is monolingual\n",
    "    compute_type=compute_type\n",
    ")\n",
    "\n",
    "audio   = whisperx.load_audio(audio_file)\n",
    "result  = model.transcribe(audio, batch_size=batch_size)\n",
    "\n",
    "align_model, metadata = whisperx.load_align_model(\n",
    "    language_code=result[\"language\"], device=device\n",
    ")\n",
    "result = whisperx.align(result[\"segments\"], align_model, metadata,\n",
    "                        audio, device, return_char_alignments=False)\n",
    "\n",
    "diarize_model   = whisperx.diarize.DiarizationPipeline(\n",
    "    use_auth_token=\"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\", device=device\n",
    ")\n",
    "diarize_segments = diarize_model(audio)\n",
    "result = whisperx.assign_word_speakers(diarize_segments, result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e96c65a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'word': 'could', 'start': np.float64(0.031), 'end': np.float64(0.211), 'score': np.float64(0.229), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'you', 'start': np.float64(0.231), 'end': np.float64(0.312), 'score': np.float64(0.697), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'tell', 'start': np.float64(0.372), 'end': np.float64(0.532), 'score': np.float64(0.912), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'me', 'start': np.float64(0.552), 'end': np.float64(0.632), 'score': np.float64(0.988), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'about', 'start': np.float64(0.692), 'end': np.float64(0.933), 'score': np.float64(0.969), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'it?', 'start': np.float64(0.973), 'end': np.float64(1.033), 'score': np.float64(0.962), 'speaker': 'SPEAKER_01'}\n",
      "{'word': 'uh', 'start': np.float64(1.053), 'end': np.float64(2.456), 'score': np.float64(0.914), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'it', 'start': np.float64(2.797), 'end': np.float64(2.937), 'score': np.float64(0.787), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'was', 'start': np.float64(4.14), 'end': np.float64(4.2), 'score': np.float64(0.002), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'late', 'start': np.float64(4.22), 'end': np.float64(4.501), 'score': np.float64(0.629), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'in', 'start': np.float64(4.701), 'end': np.float64(4.781), 'score': np.float64(0.978), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'December', 'start': np.float64(4.861), 'end': np.float64(5.603), 'score': np.float64(0.91), 'speaker': 'SPEAKER_00'}\n",
      "{'word': '.', 'start': np.float64(5.623), 'end': np.float64(5.643), 'score': np.float64(0.998), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'I', 'start': np.float64(6.645), 'end': np.float64(6.705), 'score': np.float64(0.927), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'was', 'start': np.float64(6.765), 'end': np.float64(6.926), 'score': np.float64(0.989), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'alone', 'start': np.float64(6.966), 'end': np.float64(8.309), 'score': np.float64(0.861), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'in', 'start': np.float64(8.349), 'end': np.float64(8.649), 'score': np.float64(0.862), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'my', 'start': np.float64(8.75), 'end': np.float64(8.99), 'score': np.float64(0.943), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'small', 'start': np.float64(9.03), 'end': np.float64(9.672), 'score': np.float64(0.891), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'house', 'start': np.float64(9.792), 'end': np.float64(10.213), 'score': np.float64(0.875), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'uh', 'start': np.float64(11.455), 'end': np.float64(11.496), 'score': np.float64(0.35), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'behind', 'start': np.float64(12.257), 'end': np.float64(12.838), 'score': np.float64(0.987), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'my', 'start': np.float64(12.919), 'end': np.float64(13.279), 'score': np.float64(0.949), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'uh', 'start': np.float64(13.58), 'end': np.float64(13.62), 'score': np.float64(0.478), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'uh', 'start': np.float64(15.163), 'end': np.float64(15.203), 'score': np.float64(0.005), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'a', 'start': np.float64(15.223), 'end': np.float64(15.264), 'score': np.float64(0.814), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'friend', 'start': np.float64(15.364), 'end': np.float64(15.725), 'score': np.float64(0.703), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'from', 'start': np.float64(15.805), 'end': np.float64(15.965), 'score': np.float64(0.367), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'my', 'start': np.float64(16.065), 'end': np.float64(16.426), 'score': np.float64(0.981), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'uh', 'start': np.float64(16.947), 'end': np.float64(16.987), 'score': np.float64(0.38), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'daughters', 'start': np.float64(17.609), 'end': np.float64(18.23), 'score': np.float64(0.354), 'speaker': 'SPEAKER_00'}\n",
      "{'word': '.', 'start': np.float64(18.25), 'end': np.float64(19.212), 'score': np.float64(0.979), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'and', 'start': np.float64(19.232), 'end': np.float64(19.352), 'score': np.float64(0.929), 'speaker': 'SPEAKER_00'}\n",
      "{'word': 'um', 'start': np.float64(19.513), 'end': np.float64(19.693), 'score': np.float64(0.828), 'speaker': 'SPEAKER_00'}\n"
     ]
    }
   ],
   "source": [
    "for w in result['word_segments']:\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1: could you tell me about it?\n",
      "S0: uh it was late in December. I was alone in my small house uh behind my uh uh a friend from my uh daughters. and um\n"
     ]
    }
   ],
   "source": [
    "# ── build pretty dialogue ───────────────────────────────────────────────────────\n",
    "printer_parts      = []          # will hold each finished speaker line\n",
    "current_speaker    = None\n",
    "current_line_words = []\n",
    "\n",
    "for w in result[\"word_segments\"]:\n",
    "    speaker = w[\"speaker\"]\n",
    "    word    = w[\"word\"]\n",
    "\n",
    "    # ① change of speaker  →  flush previous line\n",
    "    if speaker != current_speaker:\n",
    "        if current_line_words:\n",
    "            label = f\"S{int(current_speaker.split('_')[-1])}\"   # S0, S1, …\n",
    "            printer_parts.append(f\"{label}: \" + \" \".join(current_line_words))\n",
    "            current_line_words = []\n",
    "        current_speaker = speaker\n",
    "\n",
    "    # ② attach punctuation tokens to the previous word\n",
    "    if word and word[0] in \".,;?!:\" and current_line_words:\n",
    "        current_line_words[-1] += word        # no extra space\n",
    "    else:\n",
    "        current_line_words.append(word)       # normal word, keep the space\n",
    "\n",
    "# ③ flush the last speaker line\n",
    "if current_line_words:\n",
    "    label = f\"S{int(current_speaker.split('_')[-1])}\"\n",
    "    printer_parts.append(f\"{label}: \" + \" \".join(current_line_words))\n",
    "\n",
    "printer = \"\\n\".join(printer_parts)\n",
    "print(printer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
